---
title: "Projet de Séries Temporelles: modélisation ARIMA"
author: "Conrad Thiounn et Léo Houairi"
date: "14/04/2022"
output:
  bookdown::pdf_document2:
    toc: yes
    toc_depth: 2
    toc_title: Table des matières
  pdf_document:
    toc: yes
    toc_depth: '2'
sansfont: Times New Roman
fontsize: 12pt
header-includes: \renewcommand*\contentsname{Table des matières}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#install.packages('tinytex')
#tinytex::install_tinytex()
```

```{r chargement, include=FALSE}
require(zoo)
require(tseries)
require(fUnitRoots)
require(forecast)

## Importation des données 

datafile <- "data/valeurs_mensuelles.csv"
data <- read.csv(datafile, sep=";", skip = 3, col.names =c("mois", "valeur", "A"))
data <- data[,-3] # Suppression de la colonne inutile

dates_char <- data$mois
dates_char[1]; dates_char[length(dates_char)] # Janvier 1990 à Février 2022
dates <- as.yearmon(seq(from = 1990+0/12, to = 2022+1/12, by = 1/12))


## Premiers graphiques

indice <- zoo(data$valeur, order.by = dates) # C'est bien la liste précédente qui est utile
dindice <- diff(indice, 1) # Différence première
```

\newpage

# Partie 1 : Les données {-}

## 1 - Série choisie {-}

La série choisie représente l'indice de la production industrielle de la fabrication de machines agricoles et forestières, élaborée à partir des enquêtes de branche de l'Insee. Elle est exprimée en base 100, avec pour année de référence 2015 et a fait l'objet de deux corrections des variations saisonnières et des effets de calendrier (CVS-CJO) à l'aide de la méthode X13-Arima. Les corrections CVS-CJO ont été calculées sur deux sous-périodes dénommées "le Passé" et "le Courant" délimitées par l'année 2005. "Le Courant" est composé des observations de l'année 2005 et posterieures tandis que "le Passé" est composées des observations antérieurs à 2005. Les observations sont mensuelles et sont comprises entre janvier 1990 et février 2022.


La fabrication de machines agricoles et forestières est repertoriée dans la nomenclature d'activité française (NAF rév. 2) sous le poste 28.3. La nomenclature NAF Rév. 2 date de janvier 2008 : il est possible d'observer des ruptures de tendances liées à ce changement, dues à des éventuels changements entre la NAF Rév. 1 et la NAF Rev. 2, de reclassement de produits ou de classes.

La fabrication comprend notamment la fabrication de charrues, de tracteurs et de machines à traire. L'analyse temporelle de l'indice de la production industrielle permet de rendre compte de l'évolution de la valeur ajoutée du secteur concerné.

## 2 - Transformation {-}

La série choisie ne semble pas être stationnaire. Le chronogramme ressemble à une marche aléatoire (voir haut de la figure \@ref(fig:chronogramme).)

### 2.1 Non-stationnarité de la série initiale {-}

Afin de statuer sur la stationnarité de la série initiale, nous testons dans un premier temps si la série présente une tendance linéaire déterministe en régressant la série sur le temps. La régression linéaire donne des coefficients non significatifs aux seuils usuels. On conclut donc à l'absence d'une tendance linéaire déterministe observable. Le tableau des résultats de cetter régression linéaire est disponible en annexe \@ref(regindice).

Nous testons alors la présence d'une composante stochastique à l'aide des tests de Dickey-Fuller augmentés (DF) et de Phillips-Perron (PP).

Les tests de DF augmentés ne sont valides que si les résidus ne sont pas corrélés. On effectue donc des tests incorporant de plus en plus de retards jusqu'à ce qu'un test soit valide (résidus non-corrélés). La vérification de la non-corrélation des résidus se fait grâce à un test de Ljung-Box.
Puisque ni ordonnée à l'origine ni tendance déterministe ne sont significatifs, la spécification du test de DF est "nc". C'est-à-dire qu'on inclut dans les hypothèses nulles et alternatives ni ordonnée à l'origine ni tendance déterministe linéaire. 
Le premier test de Dickey-Fuller valide avec des résidus non corrélés incorpore 5 retards. La p-value associée est de 0.38, largement supérieure au seuil usuel de 5%. Par conséquent, on ne rejette pas l'hypothèse de nulle de non-stationnarité. Il semble donc que la série initiale est non-stationnaire.

```
Title:
 Augmented Dickey-Fuller Test

Test Results:
  PARAMETER:
    Lag Order: 5
  STATISTIC:
    Dickey-Fuller: -0.73
  P VALUE:
    0.3837 
```

** Du coup on parle du test de PP mais on ne l'utilise pas sur la série brute ?**


### 2.1 Stationnarité de la série différenciée {-}

Nous effectuons la même méthodologie que sur la série brute et commençons par tester la présence d'une tendance linéaire déterministe. La régression linéaire conduit également des coefficients non significatifs aux seuils usuels. On conclut à nouveau à l'absence d'une tendance linéaire déterministe pour la série différenciée. Le tableau des résultats de cetter régression linéaire est disponible en annexe \@ref(regdindice).

A nouveau, la spécification du test de DF est "nc". 
Le premier test de Dickey-Fuller valide avec des résidus non corrélés incorpore 4 retards. La p-value associée à ce test est de 0.01, on rejette donc l'hypothèse nulle à tous les seuils usuels. Puisque l'hypothèse nulle est la non-stationnarité, il semble donc que la série différenciée soit stationnaire.  

```
Title:
 Augmented Dickey-Fuller Test

Test Results:
  PARAMETER:
    Lag Order: 4
  STATISTIC:
    Dickey-Fuller: -12.356
  P VALUE:
    0.01 
```

Le test de Phillips-Perron nous mène la même conclusion. Il inclut 5 retards et conduit à rejeter l'hypothèse nulle de non-stationnarité (p-value=0.01).

```
	Phillips-Perron Unit Root Test

data:  dindice
Dickey-Fuller Z(alpha) = -401.19, Truncation lag parameter = 5, p-value = 0.01
alternative hypothesis: stationary
```
l
Enfin, Le test de stationnarité KPSS est associé à une p-value de 0.1. On ne rejette donc pas l'hypothèse nulle au seuil de 5%. Pour ce test, l'hypothèse nulle est la stationnarité et la série différenciée semble donc stationnaire.

```
	KPSS Test for Level Stationarity

data:  dindice
KPSS Level = 0.027926, Truncation lag parameter = 5, p-value = 0.1
```

Etant donné que les 3 tests utilisés mènent à la même conclusion, on est relativement confiants pour dire que la série différenciée est stationnaire. 

## 3 - Graphiques {-}

```{R chronogramme, echo=FALSE, fig.cap="Chronogramme de la série brute et de la série différenciée", out.width = '100%'}

plot(cbind(indice, dindice), main="Série brute et série transformée")
```
**Commentaires sur les graphiques**. 
La série non-différenciée (indice, haut de la figure) est clairement non-stationnaire. Elle fait apparaître des tendances linéaires sur certains intervalles, tendances qui finissent par s'inverser, ce qui fait penser à une marche aléatoire.
La série différenciée (dindice, bas de la figure) fait bien plus penser à une série stationnaire. Il reste cependant certaines valeurs extrêmes un peu avant 2010 et un peu après 2020. 

# Partie 2 : Modèles ARMA

## 4 - Choix de l'ARMA {-}

```{R ACF PACF, echo=FALSE, fig.cap="Autocorrélogramme et autocorélogramme partiel", out.width = '100%'}
x = dindice # Le x sur lequel on travaille est la série différenciée

par(mfrow=c(1,2))
acf(x,main="Autocorrélogramme"); pacf(x,main="Autocorrélogramme partiel")
```

L'analyse de l'autocorrélogramme empirique, conjointement avec l'autocorrélogramme partiel empirique ne nous permet pas de nous diriger d'emblée vers une modélisation par un modèle AR ou  un modèle MA. Nous allons donc avoir recours à des modèles ARMA (ARMA pour la série différenciée, donc ARIMA pour la série brute). Noter que l'abscisse du graphique est ici en années et non en mois. 

* L'étude de l'autocorrélogramme empirique nous conduit à choisir qmax = 2. Nous choisissons d'ignorer la valeur très légèrement significative à 24 mois. 
* L'étude de l'autocorrélogramme partiel nous conduit à choisir pmax = 5. Ici également, nous choisissons d'ignorer les valeurs légèrement significatives à des retards de 1.5 et 2 années.

Des valeurs significatives pour des retards élevés pourraient signaler une certaine saisonnalité. Mais nous choisissons de ne pas explorer cette voie étant donnée que notre série est censée être désaisonnalisée et que l'énoncé demande d'étudier un ARIMA.

Maintenant que nous avons choisir pmax = 5 et qmax = 2, nous utilisons les critères AIC et BIC pour sélectionner des modèles. Ces critères doivent être minimisés.


Avec le critère **AIC**, nous retenons un modèle ARMA(5,0) pour la série différenciée et donc un modèle ARIMA(5,1,0) pour la série initiale. La sortie ci-dessous indique les valeurs des coefficients de ce modèle. 

```
Call:
arima(x = indice, order = c(5, 1, 0), include.mean = F)

Coefficients:
          ar1      ar2      ar3      ar4      ar5
      -0.3166  -0.2305  -0.1163  -0.1750  -0.1449
s.e.   0.0506   0.0531   0.0551   0.0545   0.0535

sigma^2 estimated as 124.2:  log likelihood = -1474.59,  aic = 2961.19
```
```{r}
0.1449/0.0535
```

Le modèle est bien ajusté car le coefficient d'ordre le plus élevé est significatif. En effet, sa t-statistique est supérieure à 1.96 en valeur absolue et on peut donc rejeter l'hypothèse nulle de nullité du coefficient au seuil de 5%.

Il faut alors vérifier que le modèle est valide, c'est-à-dire que les résidus ne sont pas corrélés. Un test de Ljung-Box pour des retards allant jusqu'à 24 est effectué, et l'hypothèse nulle de non-corrélation des résidus ne sont pas rejetés. Par conséquent, on conclut que le modèle est valide.


Avec le critère **BIC**, nous retenons un modèle ARMA(1,1) pour la série différenciée et donc un modèle ARIMA(1,1,1) pour la série initiale. La sortie ci-dessous indique les valeurs des coefficients de ce modèle. 

```
arima(x = indice, order = c(1, 1, 1), include.mean = F)

Coefficients:
         ar1      ma1
      0.4006  -0.7190
s.e.  0.1029   0.0778

sigma^2 estimated as 126.1:  log likelihood = -1477.6,  aic = 2961.19
```
```{r}
0.4/0.1
0.71/0.0778
```
Les t-statistiques associés aux deux coefficients d'ordre les plus élevés sont supérieures à 1.96 en valeur absolue et on peut donc rejeter à 5% l'hypothèse nulle de nullité de ces coefficients. Le modèle est donc bien ajusté.

Comme précédemment, on vérifie que le modèle est valide via un test de Ljung-Box vérifiant la no-corrélation des résidus. A nouveau, l'hypothèse nulle de non-corrélation des résidus n'est rejetée pour aucun retard jusqu'à 24 et le modèle est donc valide. 

Nous disposons à ce stade de deux modèles ARIMA différents, tous deux bien ajustés et valides. 
L'étude de la série tronquée des observations antérieures à 2005 (date de coupure entre "le Passé" et "le Courant") nous donne par sélection par le BIC ou l'AIC, une modélisation ARIMA(1,1,1). Dans la suite du projet, nous présentons donc uniquement la modélisation ARIMA(1,1,1).


## 5 - Ecriture de l'ARIMA {-}

Nous donnons ci-dessous l'écriture du modèle ARIMA(1,1,1):

$$\left( 1 -  \varphi L \right)
(1-L) X_t
= \left( 1 +\theta L \right) \varepsilon_t \,$$
avec $\hat\varphi = 0.4006$ et $\hat\theta =  -0.7190$ et où L est l'opérateur de retard (souvent noté B).

# Partie 3 : Prévision {-}

## 6 - Equation régions de confiance pour les prévisions à T+1 et T+2 {-}

Pour le modèle ARIMA(1,1,1):
On note $\hat{X}_{T+1|T}$ la meilleure prédiction de X au temps T+1 sachant les X précédents. On néglige l'incertitude due à la variance dans l'estimation des paramètres du modèle. On sait que la meilleure prédiction à l'horizon T+1 ne peut pas prendre en compte l'innovation en T+1, dit autrement: 

$$ \tilde{X}_{T+1} = X_{T+1} - \hat{X}_{T+1|T} = \epsilon_{T+1}$$
Au temps T+2, la situation est un peu différente puisqu'il faut également prendre en compte l'innovation au temps T+1. On a:
$$ \tilde{X}_{T+2} = X_{T+2} - \hat{X}_{T+2|T} = \epsilon_{T+2} + \varphi\epsilon_{T+1}$$
En notant $\boldsymbol{\tilde{X}} = (\tilde{X}_{T+1}, \tilde{X}_{T+2})'$, on a alors

$$\boldsymbol{\tilde{X}} \sim \mathcal{N}(0, \Sigma) $$
Avec:

$$\Sigma = \begin{bmatrix}
\sigma^2_{\epsilon} & \phi\sigma^2_{\epsilon}\\
\phi\sigma^2_{\epsilon} & (1+\phi^2)\sigma^2_{\epsilon}
\end{bmatrix}$$

Si cette matrice est inversible, on a :
$$\boldsymbol{\tilde{X}}^T\Sigma^{-1}\boldsymbol{\tilde{X}} \sim \chi(2)$$
On peut alors utiliser cette statistique de test pour construire un intervalle de confiance bivarié pour les 2 valeurs futures. On peut également retrouver les intervalles de confiance univariés pour $X_{T+1}$ et $X_{T+2}$:

$$IC_{95\%}(X_{T+1}) = [\hat{X}_{T+1|T} - 1.96 \times \hat{\sigma}_{\epsilon}, \hat{X}_{T+1|T} + 1.96 \times \hat{\sigma}_{\epsilon}]$$
$$IC_{95\%}(X_{T+2}) = [\hat{X}_{T+2|T} - 1.96 \times \hat{\sigma}_{\epsilon} \times \sqrt{(1+\hat{\varphi}^2)}, \hat{X}_{T+2|T} + 1.96 \times \hat{\sigma}_{\epsilon} \times \sqrt{(1+\hat{\varphi}^2)}]$$

## 7 - Hypothèses utilisées pour consturire la région de confiance {-}

Les hypothèses utilisées pour obtenir cette région sont les suivantes : 

1. On suppose que les $\varepsilon_t$ sont gaussiens iid. Cette hypothèse est absolument centrale pour avoir un vecteur gaussien et en déduire des statistiques de test. 
2. On suppose que les coefficients estimées sont les vrais coefficients du modèle et que le modèle st bien spécifié
3. On suppose que la variance des $\varepsilon_t$ est non nulle et estimable par $\hat\sigma^2$

## 8 - Représentation graphique de la région de confiance {-}

``` 8. Représenter graphiquement cette région pour alpha = 95%. Commenter. ```

```{R predict, echo=FALSE, fig.cap="Prédiction des mois de mars et d'avril 2022", fig.pos = 'h!', out.width= "60%"}
arima111 <- arima(indice, c(1,1,1), include.mean = F)
plot(forecast(arima111, h =2, level = 95), xlim=c(2020, 2022.2), main="Prédiction de l'IPI Fabrication de machines agricoles et forestières")
```
On affiche ci-dessus les 2 prédictions ainsi que leurs intervalles de confiance à 95%. L'ensemble de la série n'est pas affichée afin que les valeurs prédites soient bien visibles. On constate que l'intervalle de confiance est plus large pour la valeur en $T+2$ ce qui est logique: c'est cohérent avec les formules mathématiques et cela traduit notre plus grande incertitude à long-terme. 

## 9 - Question ouverte {-}

Si $Y_t$ cause instantanément $X_t$ au sens de Granger, il est possible d'utiliser $Y_{T+1}$ pour améliorer la prédiction de $X_{T+1}$. 
On peut utiliser les valeurs passées des deux séries pour tester si $Y_t$ cause $X_t$ au sens de Granger. Pour cela, on pourrait avoir recours au test de Wald, qui s'appuie sur les corrélations entre les erreurs. En effet, si $\epsilon_{X_t}$ et $\epsilon_{Y_t}$ ne sont pas corrélés, il n'est pas possible que $Y_t$ cause instantanément $X_t$ au sens de Granger. 

\newpage 

# (APPENDIX) Appendix {-}

# Annexes

## Régression linéaire sur la série brute {#regindice}

```{r, echo = FALSE}
reg <- lm(formula = indice ~ dates)
summary(reg)
```
On ne peut pas rejeter l'hypothèse nulle que les coefficients sont nuls aux seuils usuels.

## Régression linéaire sur la série diférenciée {#regdindice}

```{r, echo = FALSE}
regd <- lm(formula = dindice ~ dates[-1])
summary(regd)
```
On ne peut pas rejeter l'hypothèse nulle que les coefficients sont nuls aux seuils usuels.

## Code utilisé

```{r, eval = FALSE}
### Librairies

require(zoo)
require(tseries)
require(fUnitRoots)
require(forecast)

## Importation des données 

datafile <- "data/valeurs_mensuelles.csv"
data <- read.csv(datafile, sep=";", skip = 3, col.names =c("mois", "valeur", "A"))
data <- data[,-3] # Suppression de la colonne inutile

dates_char <- data$mois
dates_char[1]; dates_char[length(dates_char)] # Janvier 1990 à Février 2022
dates <- as.yearmon(seq(from = 1990+0/12, to = 2022+1/12, by = 1/12))


## Premiers graphiques

indice <- zoo(data$valeur, order.by = dates) # C'est bien la liste précédente qui est utile
dindice <- diff(indice, 1) # Différence première

plot(cbind(indice, dindice))

# Notre série paraît très persistent, sans tendance très visible
# On a peut-être une stochastique trend ou une racine unitaire ? 
# La sériée différenciée une fois parait stationnaire autour de 0 


## Vérification de la présence d'une tendance linéaire déterministe dans les données

reg <- lm(formula = indice ~ dates)
summary(reg)

# Comme attendu vu les graphiques, il ne semble pas y avoir de telle tendance 
# (coeff de dates par significatif)


## Fonctions pour les tests de racine unitaire

# Fonction effectuant le test d'autocorrélation des résidus 
Qtests= function(series, k, fitdf=0) {
  # series = série à analyser
  # k = nombre maximal de lags à vérifier
  # fitdf = nombre de coefficients estimés, à retirer des ddl pour le test
  pvals = apply(matrix(1:k), 1, FUN=function(l) {
    pval = if (l<=fitdf) NA else Box.test(series, lag=l, type="Ljung-Box", fitdf=fitdf)$p.value
    return(c("lag"=l,"pval"=pval))
  })
  return(t(pvals))
}

# Fonction effectuant des tests ADF jusqu'à ce que l'un d'eux soit valide
# Cad jusqu'à ce que les résidus ne soient plus corrélés
adfTest_valid <- function(series, kmax, type) {
  k <- 0
  noautocorr <- 0
  while (noautocorr == 0) {
    cat(paste0("ADF with ", k," lags: residuals OK? "))
    adf <- adfTest(series, lags =k, type = type)
    pvals <- Qtests(adf@test$lm$residuals, 24, fitdf = length(adf@test$lm$coefficients))[,2]
    if(sum(pvals<0.05, na.rm =T) == 0){
      noautocorr <- 1; cat("OK \n")}
    else cat("nope \n")
    k <- k +1
  }
  return(adf)
}

## Test de racine unitaire sur la série non-différenciée

# On teste sur la série non-différenciée pour la présence d'une racine unitaire
# On utilise "nc" puisque d'après la régression effectuée, notre série ne contient
# ni tendance temporelle déterministe ni ordonnée à l'origine
# On teste jusqu'à 24 retards
adf <- adfTest_valid(indice, 24, "nc")
adf
# Il a fallu ajouter 5 retards pour que le test soit valide
# pval = 0.38 > 0.05, AHO, on a donc une racine unitaire dans la série non-différenciée


## Test de racine unitaire sur la série différenciée 

regd <- lm(formula = dindice ~ dates[-1])
summary(regd)

# Les coefficients de la régression sur le temps ne sont pas significatifs dans 
# le cas de la série différenciée

adfd <- adfTest_valid(dindice, 24, type ="nc")
# Il a fallu ajouter 4 lags pour que le test soit valide
adfd
# pval < 0.01 donc <0.05, RHO, pas de racine unitaire 
# Donc notre série différenciée semble être stationnaire
# La série de base est donc I(1)


### Recherche d'un modèle ARMA

## Valeurs maximales de p & q

x = dindice # Le x sur lequel on travaille est la série différenciée

par(mfrow=c(1,2))
acf(x); pacf(x)
# Vu l'ACF, on prend qmax = 2 (en ignorant le pic significatif lointain, 
# il est normal qu'il y en ait quelques uns à 5%, et on veut un modèle avec peu 
# de paramètres)
# Vu le PACF, on choisit pmax = 5 (en ignorant de la même manière les pics
# lointains)
pmax = 5
qmax = 2

## Utilisation de critères d'information pour déterminer les meilleurs modèles candidats

mat <- matrix(NA, nrow = pmax+1, ncol = qmax+1)
rownames(mat) <- paste0("p= ", 0:pmax)
colnames(mat) <-paste0("q = ", 0:qmax)
AICs <- mat
BICs <- mat
pqs <- expand.grid(0:pmax, 0:qmax) # toutes les combinaisons de p et q

for (row in 1:dim(pqs)[1]){ #On boucle sur chaque pq
  p <- pqs[row, 1] # On récupère p 
  q <- pqs[row, 2] # On récupère q
  estim <- try(arima(x, c(p,0,q), include.mean= F)) # Tenter d'estimer l'ARIMA
  AICs[p+1, q+1] <- if(class(estim) == "try-error") NA else estim$aic #Assigne l'AIC
  BICs[p+1, q+1] <- if(class(estim) == "try-error") NA else BIC(estim) # Assigne le BIC
}

AICs
AICs == min(AICs)
# Le modèle (5,0) minimise l'AIC, donc on le conserve:
arima510 <- arima(indice, c(5,1,0), include.mean = F)

BICs
BICs == min(BICs)
# Le modèle (1,1) minimise le BIC, donc on le conserve:
arima111 <- arima(indice, c(1,1,1), include.mean = F)


## Significativité des coefficients des modèles sélectionnés

arima510
0.1449/0.05353
# Le modèle est bien ajusté puisque ar5/se(ar5) > 2 en valeur absolue

arima111
0.4/0.1
0.71/0.0778
# Les 2 coefficients sont bien ajustés (rapport > 2 en valeur absolue)


## Autocorrélation des résidus

Qtests(arima510$residuals, 24, fitdf = 5)
# Pour chaque valeur de lag envisagée, on ne rejette pas l'hypothèse de non-corrélation
# des résidus, l'ARIMA 510 est donc valide

Qtests(arima111$residuals, 24, fitdf = 2)
# Même conclusion pour l'ARIMA 111

# On dispose donc à ce stade de 2 modèles semblant être valides

### Prévision pour 2 périodes supplémentaires
# On peut utiliser FORECAST mais aussi PREDICT 

#6 - Equation vérifiée par la région de confiance sur 2 étapes


#7 - Hypothèses utilisées


#8 - Représentation graphique de la région et commentaire

predict(arima510, n.ahead = 2)

# Au moins les 2 commandes suivantes donnent des résultats cohérents

forecast(arima510, h = 2, level = 95)
autoplot(forecast(arima510, h =2, level = 95))

# Intervalle de confiance plus large en T+2

```

